{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e699cd97-25db-45e4-bb01-6f00fa520ff2",
   "metadata": {},
   "source": [
    "### Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3029de8f-7fce-45d0-8d4e-53433f8661e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "fablib = fablib_manager() \n",
    "conf = fablib.show_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46cb8a3-d55e-4a9a-add2-0c3907f101ac",
   "metadata": {},
   "source": [
    "### Define configuration for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8fa5ac-e3e4-47f5-987e-bb42ed21d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_name=\"tcp-ecn\" + fablib.get_bastion_username()\n",
    "\n",
    "node_conf = [\n",
    " {'name': \"tx0\",    'cores': 4, 'ram': 32, 'disk': 20, 'image': 'default_ubuntu_22', 'packages': ['iperf3', 'net-tools', 'moreutils']}, \n",
    " {'name': \"router\", 'cores': 4, 'ram': 32, 'disk': 20, 'image': 'default_ubuntu_22', 'packages': ['iperf3', 'net-tools', 'moreutils']}, \n",
    " {'name': \"delay\", 'cores': 4, 'ram': 32, 'disk': 20, 'image': 'default_ubuntu_22', 'packages': ['iperf3', 'net-tools', 'moreutils']}, \n",
    " {'name': \"rx0\",    'cores': 4, 'ram': 32, 'disk': 20, 'image': 'default_ubuntu_22', 'packages': ['iperf3', 'net-tools', 'moreutils']}, \n",
    "]\n",
    "net_conf = [\n",
    " {\"name\": \"net-tx\", \"subnet\": \"10.0.0.0/24\", \"nodes\": [{\"name\": \"tx0\",   \"addr\": \"10.0.0.100\"}, {\"name\": \"delay\", \"addr\": \"10.0.0.2\"}]},\n",
    " {\"name\": \"net-delay-router\", \"subnet\": \"10.0.2.0/24\", \"nodes\": [{\"name\": \"delay\",   \"addr\": \"10.0.2.2\"}, {\"name\": \"router\", \"addr\": \"10.0.2.1\"}]},\n",
    " {\"name\": \"net-rx\", \"subnet\": \"10.0.5.0/24\", \"nodes\": [{\"name\": \"router\",   \"addr\": \"10.0.5.1\"}, {\"name\": \"rx0\", \"addr\": \"10.0.5.100\"},]}\n",
    "\n",
    "]\n",
    "route_conf = [\n",
    " {\"addr\": \"10.0.5.0/24\", \"gw\": \"10.0.0.2\", \"nodes\": [\"tx0\"]}, \n",
    " {\"addr\": \"10.0.5.0/24\", \"gw\": \"10.0.2.1\", \"nodes\": [\"delay\"]},\n",
    "\n",
    " {\"addr\": \"10.0.0.0/24\", \"gw\": \"10.0.5.1\", \"nodes\": [\"rx0\"]},\n",
    " {\"addr\": \"10.0.0.0/24\", \"gw\": \"10.0.2.2\", \"nodes\": [\"router\"]}\n",
    "\n",
    "]\n",
    "exp_conf = {'cores': sum([ n['cores'] for n in node_conf]), 'nic': sum([len(n['nodes']) for n in net_conf]) }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671606b1-5114-4ed2-a45d-2aedb9715d51",
   "metadata": {},
   "source": [
    "### Reserve resources\n",
    "\n",
    "Now, we are ready to reserve resources!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c18d7f0-b22f-4f51-959d-1625d8975731",
   "metadata": {},
   "source": [
    "First, make sure you don’t already have a slice with this name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979c6a12-8ef0-41c2-95c1-a0d6992c696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    slice = fablib.get_slice(slice_name)\n",
    "    print(\"You already have a slice by this name!\")\n",
    "    print(\"If you previously reserved resources, skip to the 'log in to resources' section.\")\n",
    "except:\n",
    "    print(\"You don't have a slice named %s yet.\" % slice_name)\n",
    "    print(\"Continue to the next step to make one.\")\n",
    "    slice = fablib.new_slice(name=slice_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040ba302-135e-4801-b1e0-9494ce668fce",
   "metadata": {},
   "source": [
    "We will select a random site that has sufficient resources for our experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973c997-62d8-452d-9022-864b8dc822c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    site_name = fablib.get_random_site()\n",
    "    if ( (fablib.resources.get_core_available(site_name) > 1.2*exp_conf['cores']) and\n",
    "        (fablib.resources.get_component_available(site_name, 'SharedNIC-ConnectX-6') > 1.2**exp_conf['nic']) ):\n",
    "        break\n",
    "\n",
    "fablib.show_site(site_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6010c4-245b-4589-b827-5a0ac31b728a",
   "metadata": {},
   "source": [
    "Then we will add hosts and network segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9ef98c-0a2d-4ed6-b7f3-0adbf4ae1d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell sets up the nodes\n",
    "for n in node_conf:\n",
    "    slice.add_node(name=n['name'], site=site_name, \n",
    "                   cores=n['cores'], \n",
    "                   ram=n['ram'], \n",
    "                   disk=n['disk'], \n",
    "                   image=n['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b2f24e-06dd-4f45-8a0f-3ca287821f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell sets up the network segments\n",
    "for n in net_conf:\n",
    "    ifaces = [slice.get_node(node[\"name\"]).add_component(model=\"NIC_Basic\", \n",
    "                                                 name=n[\"name\"]).get_interfaces()[0] for node in n['nodes'] ]\n",
    "    slice.add_l2network(name=n[\"name\"], type='L2Bridge', interfaces=ifaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd98e9c9-fcd8-45bd-bafe-9cfadfd369a6",
   "metadata": {},
   "source": [
    "The following cell submits our request to the FABRIC site. The output of this cell will update automatically as the status of our request changes.\n",
    "\n",
    "-   While it is being prepared, the “State” of the slice will appear as “Configuring”.\n",
    "-   When it is ready, the “State” of the slice will change to “StableOK”.\n",
    "\n",
    "You may prefer to walk away and come back in a few minutes (for simple slices) or a few tens of minutes (for more complicated slices with many resources)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad95a3c-fd11-475c-94b1-cf1587666663",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b415d743-5ee5-4029-ab5e-1391d645c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice.get_state()\n",
    "slice.wait_ssh(progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34b617c-2e5c-40c3-98fc-73be3183b5f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extend your slice\n",
    "\n",
    "If you don’t plan to finish an experiment in one day, you can extend your slice. The following cell extends your reservation for 7 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4b068-005a-4fbf-ad31-89dccc85dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from datetime import timedelta\n",
    "\n",
    "# Set end date to 7 days from now\n",
    "end_date = (datetime.now(timezone.utc) + timedelta(days=7)).strftime(\"%Y-%m-%d %H:%M:%S %z\")\n",
    "slice.renew(end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4ac5bb-61a3-423f-a549-7df87336f1cf",
   "metadata": {},
   "source": [
    "### Configure Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7be6120-53f8-4e0e-a621-417074fcbce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for node in slice.get_nodes():\n",
    "    # Download and unzip the kernel package\n",
    "    node.execute(\"wget https://github.com/L4STeam/linux/releases/download/testing-build/l4s-testing.zip\")\n",
    "    node.execute(\"sudo apt install unzip\")\n",
    "    node.execute(\"unzip l4s-testing.zip\")\n",
    "    \n",
    "    # Install the kernel packages and update GRUB\n",
    "    node.execute(\"sudo dpkg --install debian_build/*\")\n",
    "    node.execute(\"sudo update-grub\")\n",
    "    node.execute(\"sudo reboot\")\n",
    "\n",
    "# wait for all nodes to come back up\n",
    "slice.wait_ssh(progress=True)\n",
    "for node in slice.get_nodes():\n",
    "    # check kernel version\n",
    "    node.execute(\"hostname; uname -a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30dedc-b0a7-4163-9e94-af44100ae30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inital configuration for the senders\n",
    "slice.get_node(name=\"tx0\").execute(\"sudo sysctl -w net.ipv4.tcp_congestion_control=cubic\")\n",
    "slice.get_node(name=\"tx0\").execute(\"sudo sysctl -w net.ipv4.tcp_ecn=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431d14f4-2355-48cd-bd75-097ac501f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuration for DUALPI2 bottleneck\n",
    "cmd_dualpi2=\"\"\"sudo apt-get update\n",
    "sudo apt -y install git gcc make bison flex libdb-dev libelf-dev pkg-config libbpf-dev libmnl-dev libcap-dev libatm1-dev selinux-utils libselinux1-dev\n",
    "sudo git clone https://github.com/L4STeam/iproute2.git\n",
    "cd iproute2\n",
    "sudo chmod +x configure\n",
    "sudo ./configure\n",
    "sudo make\n",
    "sudo make install\"\"\"\n",
    "slice.get_node(name=\"router\").execute(cmd_dualpi2)\n",
    "slice.get_node(name=\"router\").execute(\"sudo modprobe sch_dualpi2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24abb79-8cf0-4175-a405-56265ccf0538",
   "metadata": {},
   "source": [
    "### Configure resources\n",
    "\n",
    "Next, we will configure the resources so they are ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddebb2cd-42fb-48d5-962b-11f30e68f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(name=slice_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7f6d80-3d38-4943-9c1a-60d92c3d0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages\n",
    "# this will take a while and will run in background while you do other steps\n",
    "for n in node_conf:\n",
    "    if len(n['packages']):\n",
    "        node = slice.get_node(n['name'])\n",
    "        pkg = \" \".join(n['packages'])\n",
    "        node.execute_thread(\"sudo apt update; sudo apt -y install %s\" % pkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96e4be-1a50-4a6f-b579-9fcb1ffd843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring interfaces up and either assign an address (if there is one) or flush address\n",
    "from ipaddress import ip_address, IPv4Address, IPv4Network\n",
    "\n",
    "for net in net_conf:\n",
    "    for n in net['nodes']:\n",
    "        if_name = n['name'] + '-' + net['name'] + '-p1'\n",
    "        iface = slice.get_interface(if_name)\n",
    "        iface.ip_link_up()\n",
    "        if n['addr']:\n",
    "            iface.ip_addr_add(addr=n['addr'], subnet=IPv4Network(net['subnet']))\n",
    "        else:\n",
    "            iface.get_node().execute(\"sudo ip addr flush dev %s\"  % iface.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bcf2bf-b8ec-4be8-8be8-09cdc19259d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a \"hosts\" file that has names and addresses of every node\n",
    "hosts_txt = [ \"%s\\t%s\" % ( n['addr'], n['name'] ) for net in net_conf  for n in net['nodes'] if type(n) is dict and n['addr']]\n",
    "for n in slice.get_nodes():\n",
    "    for h in hosts_txt:\n",
    "        n.execute(\"echo %s | sudo tee -a /etc/hosts\" % h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04674abd-afec-4f16-9513-9ae81b4cfca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable IPv4 forwarding on all nodes\n",
    "for n in slice.get_nodes():\n",
    "    n.execute(\"sudo sysctl -w net.ipv4.ip_forward=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd32e9b-0ad6-48ec-b7a3-95380bd73862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up static routes\n",
    "for rt in route_conf:\n",
    "    for n in rt['nodes']:\n",
    "        slice.get_node(name=n).ip_route_add(subnet=IPv4Network(rt['addr']), gateway=rt['gw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2507e702-bc51-40af-a4b3-a6a015db40ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off segmentation offload on interfaces\n",
    "for iface in slice.get_interfaces():\n",
    "    iface_name = iface.get_device_name()\n",
    "    n = iface.get_node()\n",
    "    offloads = [\"gro\", \"lro\", \"gso\", \"tso\"]\n",
    "    for offload in offloads:\n",
    "        n.execute(\"sudo ethtool -K %s %s off\" % (iface_name, offload))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03518528-84bc-4eed-a9b0-33ef803ce901",
   "metadata": {},
   "source": [
    "### Draw the network topology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486469db-835d-4fdb-9923-fa6101699c09",
   "metadata": {},
   "source": [
    "The following cell will draw the network topology, for your reference. The interface name and addresses of each experiment interface will be shown on the drawing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a30b5-fade-4b89-98e1-9d757f0a0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_nets = [(n.get_name(), {'color': 'lavender'}) for n in slice.get_l2networks() ]\n",
    "l3_nets = [(n.get_name(), {'color': 'pink'}) for n in slice.get_l3networks() ]\n",
    "hosts   =   [(n.get_name(), {'color': 'lightblue'}) for n in slice.get_nodes()]\n",
    "nodes = l2_nets + l3_nets + hosts\n",
    "ifaces = [iface.toDict() for iface in slice.get_interfaces()]\n",
    "edges = [(iface['network'], iface['node'], \n",
    "          {'label': iface['physical_dev'] + '\\n' + iface['ip_addr'] + '\\n' + iface['mac']}) for iface in ifaces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f1f8a5-cd7c-4784-a694-7c09f73e26dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(len(nodes),len(nodes)))\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, node_shape='s',  \n",
    "        node_color=[n[1]['color'] for n in nodes], \n",
    "        node_size=[len(n[0])*400 for n in nodes],  \n",
    "        with_labels=True);\n",
    "nx.draw_networkx_edge_labels(G,pos,\n",
    "                             edge_labels=nx.get_edge_attributes(G,'label'),\n",
    "                             font_color='gray',  font_size=8, rotate=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cf46b8-310f-4893-af93-4389ec882afe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Log into resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5c2ac5-ee82-4bc8-b568-a423f4a6197d",
   "metadata": {},
   "source": [
    "Now, we are finally ready to log in to our resources over SSH! Run the following cells, and observe the table output - you will see an SSH command for each of the resources in your topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e3e270-0d37-4f59-bf9a-591450653259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "slice_info = [{'Name': n.get_name(), 'SSH command': n.get_ssh_command()} for n in slice.get_nodes()]\n",
    "pd.DataFrame(slice_info).set_index('Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe26bfb9-6ada-45bf-86d4-e36519bd78f3",
   "metadata": {},
   "source": [
    "Now, you can open an SSH session on any of the resources as follows:\n",
    "\n",
    "-   in Jupyter, from the menu bar, use File \\> New \\> Terminal to open a new terminal.\n",
    "-   copy an SSH command from the table, and paste it into the terminal. (Note that each SSH command is a single line, even if the display wraps the text to a second line! When you copy and paste it, paste it all together.)\n",
    "\n",
    "You can repeat this process (open several terminals) to start a session on each resource. Each terminal session will have a tab in the Jupyter environment, so that you can easily switch between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8b6b37-b634-4f4d-9776-ad69e6a3617c",
   "metadata": {},
   "source": [
    "### Execute Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c19512d-dc7e-4860-a7af-bd280b318a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes and instances\n",
    "\n",
    "tx0_node = slice.get_node(name=\"tx0\")\n",
    "rx0_node = slice.get_node(name=\"rx0\")\n",
    "delay_node = slice.get_node(name=\"delay\")\n",
    "router_node = slice.get_node(name=\"router\")\n",
    "\n",
    "# interfaces\n",
    "\n",
    "tx0_egress_iface  = tx0_node.get_interface(network_name = \"net-tx\")\n",
    "\n",
    "delay_ingress_tx_iface  = delay_node.get_interface(network_name = \"net-tx\")\n",
    "delay_egress_iface  = delay_node.get_interface(network_name = \"net-delay-router\")\n",
    "delay_ingress_tx_name = delay_ingress_tx_iface.get_device_name()\n",
    "delay_egress_name = delay_egress_iface.get_device_name()\n",
    "\n",
    "router_ingress_iface  = router_node.get_interface(network_name = \"net-delay-router\")\n",
    "router_egress_iface  = router_node.get_interface(network_name = \"net-rx\")\n",
    "router_egress_name  = router_egress_iface.get_device_name()\n",
    "\n",
    "\n",
    "rx0_ingress_iface  = rx0_node.get_interface(network_name = \"net-rx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ba54b-155f-4b3f-8d42-36d0b0361504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate full factorial experiment\n",
    "import itertools\n",
    "\n",
    "exp_factors = {\n",
    "    'n_bdp': [2],  # n x bandwidth delay product\n",
    "    'btl_capacity': [100], #in Mbps #'btl_capacity': [100, 1000]\n",
    "    'base_rtt': [25], # in ms #'base_rtt': [5, 10, 50, 100],\n",
    "    'aqm': ['single_queue_FQ'], #single_queue_FQ\n",
    "    'ecn_threshold': [1, 20], # in ms #'ecn_threshold': [1, 5, 20]\n",
    "    'ecn_support': [0, 1, 2],  # 0: noecn, 1: ecn, 2: accecn #'rx0_ecn': [0, 1, 2] #it will apply to both the sender and the receiver\n",
    "    'cc_tx0': [\"cubic\",\"prague\"],\n",
    "    'trial': [1] #'trial': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "factor_names = list(exp_factors.keys())\n",
    "factor_lists = itertools.product(*exp_factors.values())\n",
    "\n",
    "flow_number_tx0=1 #number of tx0 flows\n",
    "\n",
    "exp_lists = [\n",
    "    {k: v for k, v in zip(factor_names, fl) \n",
    "     if (k != 'ecn_threshold') or \n",
    "        (fl[factor_names.index('aqm')] != 'FIFO' and fl[factor_names.index('ecn_support')] != 0)}\n",
    "    for fl in factor_lists\n",
    "    if ((fl[factor_names.index('n_bdp')] * fl[factor_names.index('base_rtt')] >= fl[factor_names.index('ecn_threshold')]\n",
    "        or (fl[factor_names.index('aqm')] != 'FIFO' and fl[factor_names.index('ecn_support')] != 0))\n",
    "        and not (fl[factor_names.index('cc_tx0')] == 'prague' and \n",
    "                 not (fl[factor_names.index('ecn_threshold')] == 1 and fl[factor_names.index('ecn_support')] == 2))\n",
    "        and not (fl[factor_names.index('cc_tx0')] == 'cubic' and \n",
    "                 fl[factor_names.index('ecn_support')] == 2))\n",
    "]\n",
    "\n",
    "# Remove duplicates\n",
    "exp_lists = [dict(t) for t in {frozenset(item.items()) for item in exp_lists}]\n",
    "\n",
    "data_dir_tx0 = slice_name + 'singlebottleneck'+\"-tx0\"\n",
    "\n",
    "print(\"Number of experiments:\",len(exp_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9fab13-28bd-4f57-a5e1-c20c9d364a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run experiments\n",
    "import time\n",
    "d = 20 #duration in seconds\n",
    "\n",
    "em = [delay_ingress_tx_name, delay_egress_name]\n",
    "\n",
    "commands_noecn='''\n",
    "sudo sysctl -w net.ipv4.tcp_congestion_control=cubic  \n",
    "sudo sysctl -w net.ipv4.tcp_ecn=0''' \n",
    "\n",
    "commands_ecn='''\n",
    "sudo sysctl -w net.ipv4.tcp_congestion_control=cubic  \n",
    "sudo sysctl -w net.ipv4.tcp_ecn=1'''\n",
    "\n",
    "commands_accecn='''\n",
    "sudo sysctl -w net.ipv4.tcp_congestion_control=prague  \n",
    "sudo sysctl -w net.ipv4.tcp_ecn=3''' \n",
    "\n",
    "ecn_list=[commands_noecn, commands_ecn, commands_accecn]\n",
    "\n",
    "for exp in exp_lists:\n",
    "\n",
    "    # check if we already ran this experiment\n",
    "    # (allow stop/resume)\n",
    "    name_tx0=\"%s_%0.1f_%d_%d_%s_%s_%d_%d\" % (exp['cc_tx0'],exp['n_bdp'], exp['btl_capacity'], exp['base_rtt'], exp['aqm'], str(exp.get('ecn_threshold', 'none')), exp['ecn_support'], exp['trial'])\n",
    "    \n",
    "    file_out_tx0_json = name_tx0+\"-result.json\"\n",
    "    file_out_tx0_ss = name_tx0+\"-ss.txt\"\n",
    "    stdout_tx0_json, stderr_tx0_json = tx0_node.execute(\"ls \" + file_out_tx0_json, quiet=True) \n",
    "    stdout_tx0_ss, stderr_tx0_ss = tx0_node.execute(\"ls \" + file_out_tx0_ss, quiet=True)\n",
    "    \n",
    "    if len(stdout_tx0_json) and len(stdout_tx0_ss):\n",
    "        print(\"Already have \" + name_tx0 + \", skipping\")\n",
    "\n",
    "    elif len(stderr_tx0_json) or len(stderr_tx0_ss):\n",
    "        print(\"Running experiment to generate \" + name_tx0) \n",
    "        \n",
    "        # delay at emulator\n",
    "        for e in em:\n",
    "            cmds = \"sudo tc qdisc replace dev {iface} root netem delay {owd}ms limit 60000\".format(iface=e, owd=exp['base_rtt']/2)\n",
    "            delay_node.execute(cmds)\n",
    "        \n",
    "        # fixed values\n",
    "        btl_limit    = int(1000*exp['n_bdp']*exp['btl_capacity']*exp['base_rtt']/8) # limit of the bottleneck, n_bdp x BDP in bytes \n",
    "        packet_number=int(btl_limit/1500)+1\n",
    "         \n",
    "        #receiver ecn configuration\n",
    "        rx0_node.execute(ecn_list[exp['ecn_support']])\n",
    "        \n",
    "        #sender ecn configuration\n",
    "        tx0_node.execute(ecn_list[exp['ecn_support']])\n",
    "        \n",
    "        #aqm type selection\n",
    "        cmds_prefix = '''\n",
    "            sudo tc qdisc del dev {iface} root\n",
    "            sudo tc qdisc replace dev {iface} root handle 1: htb default 3 \n",
    "            sudo tc class add dev {iface} parent 1: classid 1:3 htb rate {capacity}mbit \n",
    "            '''.format(iface=router_egress_name, capacity=exp['btl_capacity'], buffer=btl_limit)\n",
    "        cmds_specific = {\n",
    "        'FIFO': \"sudo tc qdisc add dev {iface} parent 1:3 handle 3: bfifo limit {buffer}\".format(iface=router_egress_name, buffer=btl_limit),\n",
    "        'single_queue_FQ': \"sudo tc qdisc replace dev {iface} parent 1:3 handle 3: fq limit {packet_limit} flow_limit {packet_limit} orphan_mask 0 ce_threshold {threshold}ms\".format(iface=router_egress_name, packet_limit=packet_number, threshold=exp.get('ecn_threshold', 100)),\n",
    "        'Codel': \"sudo tc qdisc replace dev {iface} parent 1:3 handle 3: codel limit {packet_limit} target {target}ms interval 100ms ecn ce_threshold {threshold}ms\".format(iface=router_egress_name, packet_limit=packet_number, target=exp['base_rtt']*exp['n_bdp'], threshold=exp.get('ecn_threshold', 0)),\n",
    "        'FQ': \"sudo tc qdisc replace dev {iface} parent 1:3 handle 3: fq limit {packet_limit} flow_limit {packet_limit} ce_threshold {threshold}ms\".format(iface=router_egress_name, packet_limit=packet_number, threshold=exp.get('ecn_threshold', 0)),\n",
    "        'FQ_Codel': \"sudo tc qdisc replace dev {iface} parent 1:3 handle 3: fq_codel limit {packet_limit} target {target}ms interval 100ms ecn ce_threshold {threshold}ms\".format(iface=router_egress_name, packet_limit=packet_number, target=exp['base_rtt']*exp['n_bdp'], threshold=exp.get('ecn_threshold', 0)),\n",
    "        'DualPI2': \"sudo tc qdisc add dev {iface} parent 1:3 handle 3: dualpi2 target {threshold}ms\".format(iface=router_egress_name, threshold=exp.get('ecn_threshold', 0))\n",
    "        }\n",
    "\n",
    "        router_node.execute(cmds_prefix)\n",
    "        router_node.execute(cmds_specific[ exp['aqm'] ])\n",
    "            \n",
    "        rx0_node.execute(\"killall iperf3\")\n",
    "        \n",
    "        ss_tx0_script=\"rm -f {flow}-ss.txt; start_time=$(date +%s); while true; do ss --no-header -eipn dst 10.0.5.100 | ts '%.s' | tee -a {flow}-ss.txt; current_time=$(date +%s); elapsed_time=$((current_time - start_time));  if [ $elapsed_time -ge {duration} ]; then break; fi; sleep 0.1; done;\"\n",
    "        \n",
    "        rx0_node.execute(\"iperf3 -s -1 -p 4000 -D\")\n",
    "        \n",
    "        tx0_node.execute_thread(ss_tx0_script.format(flow=name_tx0, duration=d))\n",
    "        stdout, stderr =tx0_node.execute(\"sleep 1; iperf3 -c 10.0.5.100 -t {duration} -P {flows} -C {cc} -p 4000 -J > {flow}-result.json\".format(flow =name_tx0, duration=d, flows=flow_number_tx0, cc=exp['cc_tx0']))\n",
    "        time.sleep(3)  \n",
    "        \n",
    "print(\"finished\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33adbc37-7171-4c8b-9793-86319f87c892",
   "metadata": {},
   "source": [
    "### Analysis of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3136cf16-1dd7-48d7-bade-4105ee66a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in exp_lists:\n",
    "    name_tx0=\"%s_%0.1f_%d_%d_%s_%s_%d_%d\" % (exp['cc_tx0'],exp['n_bdp'], exp['btl_capacity'], exp['base_rtt'], exp['aqm'], str(exp.get('ecn_threshold', 'none')), exp['ecn_support'], exp['trial'])\n",
    "    \n",
    "    \n",
    "    file_out_tx0_csv = name_tx0+\"-ss.csv\"\n",
    "    stdout_tx0_csv, stderr_tx0_csv = tx0_node.execute(\"ls \" + file_out_tx0_csv, quiet=True) \n",
    "\n",
    "    if len(stdout_tx0_csv):\n",
    "        print(\"Already have \" + name_tx0 + \", skipping\")\n",
    "\n",
    "    elif len(stderr_tx0_csv):\n",
    "        print(\"Running to generate csv files \" + name_tx0)\n",
    "    \n",
    "        ss_tx0_script_processing=\"\"\"\n",
    "\n",
    "        f_1={types}; \n",
    "        rm -f ${{f_1}}-ss.csv;\n",
    "        cat ${{f_1}}-ss.txt | sed -e \":a; /<->$/ {{ N; s/<->\\\\n//; ba; }}\"  | grep \"iperf3\" | grep -v \"SYN-SENT\"> ${{f_1}}-ss-processed.txt; \n",
    "        cat ${{f_1}}-ss-processed.txt | awk '{{print $1}}' > ts-${{f_1}}.txt; \n",
    "        cat ${{f_1}}-ss-processed.txt | grep -oP '\\\\bcwnd:.*?(\\s|$)' | awk -F '[:,]' '{{print $2}}' | tr -d ' ' > cwnd-${{f_1}}.txt; \n",
    "        cat ${{f_1}}-ss-processed.txt | grep -oP '\\\\brtt:.*?(\\s|$)' | awk -F '[:,]' '{{print $2}}' | tr -d ' '  | cut -d '/' -f 1   > srtt-${{f_1}}.txt; \n",
    "        cat ${{f_1}}-ss-processed.txt | grep -oP '\\\\bfd=.*?(\\s|$)' | awk -F '[=,]' '{{print $2}}' | tr -d ')' | tr -d ' '   > fd-${{f_1}}.txt;\n",
    "        paste ts-${{f_1}}.txt fd-${{f_1}}.txt cwnd-${{f_1}}.txt srtt-${{f_1}}.txt -d ',' > ${{f_1}}-ss.csv;\"\"\".format(types=name_tx0)\n",
    "     \n",
    "        tx0_node.execute(ss_tx0_script_processing)\n",
    "\n",
    "tx0_node.execute('mkdir '+data_dir_tx0)\n",
    "\n",
    "tx0_node.execute('mv *.json '+ data_dir_tx0)\n",
    "tx0_node.execute('mv *.txt '+ data_dir_tx0)\n",
    "tx0_node.execute('mv *.csv '+ data_dir_tx0)\n",
    "\n",
    "tx0_node.execute('tar -czvf '+data_dir_tx0+ '.tgz ' +  data_dir_tx0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d813947-ec8c-4d45-8767-861a655bcb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_name_str = repr(slice_name)\n",
    "\n",
    "content_tx0 = f\"\"\"\n",
    "# generate full factorial experiment\n",
    "import itertools\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "exp_lists = {exp_lists}\n",
    "slice_name = {slice_name_str}\n",
    "\n",
    "data_dir_tx0 = slice_name + 'singlebottleneck' + \"-tx0\"\n",
    "\n",
    "throughput_data = {{}}  # Initialize the dictionary\n",
    "srtt_data = {{}}\n",
    "cwnd_data= pd.DataFrame()\n",
    "srtt_data_time= pd.DataFrame()\n",
    "for exp in exp_lists:\n",
    "    name_tx0=\"%s_%0.1f_%d_%d_%s_%s_%d_%d\" % (exp['cc_tx0'],exp['n_bdp'], exp['btl_capacity'], exp['base_rtt'], exp['aqm'], str(exp.get('ecn_threshold', 'none')), exp['ecn_support'], exp['trial'])\n",
    "\n",
    "    # Load the JSON output file into a Python object\n",
    "    with open(f\"/home/ubuntu/{{data_dir_tx0}}/{{name_tx0}}-result.json\") as f:\n",
    "        iperf3_data = json.load(f)\n",
    "\n",
    "    throughput_data[name_tx0] = iperf3_data['end']['sum_received']['bits_per_second'] / (1000000 * 1)  # to convert Mbit\n",
    "\n",
    "    # Average SRTT for Each Flow\n",
    "    columns = ['timestamp', 'flow ID', 'cwnd', 'srtt']\n",
    "    df_f1 = pd.read_csv(f\"/home/ubuntu/{{data_dir_tx0}}/{{name_tx0}}-ss.csv\", names=columns)\n",
    "    \n",
    "    # Filter out rows with flow ID = 4, they are for the control flows\n",
    "    df_f1 = df_f1[df_f1['flow ID'] != 4].reset_index(drop=True)\n",
    "\n",
    "    average_RTT_f1 = df_f1['srtt'].mean()\n",
    "    \n",
    "    cwnd_data[name_tx0] = df_f1['cwnd']\n",
    "    srtt_data[name_tx0] = average_RTT_f1\n",
    "    srtt_data_time[name_tx0] = df_f1['srtt']\n",
    "\n",
    "# Save throughput_data to a JSON file\n",
    "with open('throughput_data.json', 'w') as f:\n",
    "    json.dump(throughput_data, f)\n",
    "\n",
    "# Save srtt_data to a JSON file\n",
    "with open('srtt_data.json', 'w') as f:\n",
    "    json.dump(srtt_data, f)\n",
    "\n",
    "cwnd_data.to_csv(\"consolidated_cwnd_data.csv\", index=False)\n",
    "srtt_data_time.to_csv(\"time_srtt.csv\", index=False)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tx0_file_path = 'analysis_tx0.py'\n",
    "\n",
    "# Write the content to the new file\n",
    "with open(tx0_file_path, 'w') as new_file:\n",
    "    new_file.write(content_tx0)\n",
    "\n",
    "print(f\"Content written to {tx0_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01144c74-cf3a-47ce-9e29-f3a80da0ee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmds_py_install = '''\n",
    "            sudo apt-get -y install python3\n",
    "            sudo apt -y install python3-pip\n",
    "            pip install numpy\n",
    "            pip install matplotlib\n",
    "            pip install pandas\n",
    "            '''\n",
    "\n",
    "tx0_node.execute(cmds_py_install)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93728f4e-f1b3-4197-b7c7-d72062d56d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "tx0_node.upload_file(os.path.join (os.getcwd(), \"analysis_tx0.py\"),\"/home/ubuntu/analysis_tx0.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19669056-8d6a-4379-9cd3-fb81bd29664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx0_node.execute('python3 analysis_tx0.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f1c97d-8dc3-4238-90c5-22136d007416",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx0_node.download_file(\"/home/fabric/work/tput_tx0.json\",\"/home/ubuntu/throughput_data.json\")\n",
    "tx0_node.download_file(\"/home/fabric/work/srtt_tx0.json\",\"/home/ubuntu/srtt_data.json\")\n",
    "tx0_node.download_file(\"/home/fabric/work/cwnd_tx0.csv\",\"/home/ubuntu/consolidated_cwnd_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93edaf99-47fd-4dde-b284-7174a74bd85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Initialize empty variables\n",
    "throughput_data = {}\n",
    "srtt_data = {}\n",
    "\n",
    "# Directory containing JSON files\n",
    "data_directory = '/home/fabric/work/'\n",
    "\n",
    "# List of JSON files in the directory\n",
    "json_files = [f for f in os.listdir(data_directory) if f.endswith('.json')]\n",
    "\n",
    "# Load data from each JSON file and update the variables\n",
    "for file_name in json_files:\n",
    "    file_path = os.path.join(data_directory, file_name)\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Check if the file contains throughput data or srtt data based on its name\n",
    "    if 'tput' in file_name:\n",
    "        throughput_data.update(data)\n",
    "    elif 'srtt' in file_name:\n",
    "        srtt_data.update(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf14b3a-cabe-4b80-8987-07192be643d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "throughput_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62525a96-6b9d-49da-b105-b4ad78064eee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "btl_cap=int(1000*exp_factors['btl_capacity'][0]*exp_factors['base_rtt'][0]/8)\n",
    "btl_limit_noecn=int(1000*exp_factors['btl_capacity'][0]*exp_factors['base_rtt'][0]*(exp_factors['n_bdp'][0]+1)/8)\n",
    "btl_limit_20=int(1000*exp_factors['btl_capacity'][0]*(exp_factors['base_rtt'][0]+20)/8)\n",
    "btl_limit_1=int(1000*exp_factors['btl_capacity'][0]*(exp_factors['base_rtt'][0]+1)/8)\n",
    "\n",
    "packet_limits=[int(btl_limit_noecn/1500)+1, int(btl_limit_20/1500)+1,int(btl_limit_1/1500)+1, int(btl_limit_1/1500)+1]\n",
    "\n",
    "bottleneck_limit=int(btl_limit_noecn/1500)+1\n",
    "bottleneck_limit_cap=int(btl_cap/1500)+1\n",
    "\n",
    "df = pd.read_csv('/home/fabric/work/cwnd_tx0.csv')\n",
    "custom_order = ['cubic_2.0_100_25_single_queue_FQ_none_0_1', 'cubic_2.0_100_25_single_queue_FQ_20_1_1', 'cubic_2.0_100_25_single_queue_FQ_1_1_1','prague_2.0_100_25_single_queue_FQ_1_2_1']\n",
    "titles=['CUBIC - No ECN', 'CUBIC - 20 ms ECN Threshold' , 'CUBIC - 1ms ECN Threshold','Prague - 1ms ECN Threshold']\n",
    "ecn_limits=[int(btl_limit_noecn/1500)+1, int(btl_limit_20/1500)+1,int(btl_limit_1/1500)+1]\n",
    "assert set(custom_order) == set(df.columns)\n",
    "num_columns = len(df.columns)\n",
    "\n",
    "global_min_cwnd = min(df[custom_order].min())\n",
    "global_max_cwnd = max(df[custom_order].max())\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, num_columns, figsize=(5 * num_columns+6, 7))  # Adjust the figure size as needed\n",
    "\n",
    "y_limits = (global_min_cwnd, global_max_cwnd+10)\n",
    "\n",
    "# Iterate over the columns and create a subplot for each\n",
    "for i, column in enumerate(custom_order):\n",
    "    axs[i].plot(df.index, df[column])\n",
    "    axs[i].set_title(f\"{titles[i]} - Average Utilization: {format(throughput_data[column], '.2f')} %\", fontsize=14)\n",
    "    axs[i].set_xlabel('Index')\n",
    "    axs[i].set_ylim(y_limits)\n",
    "    axs[i].set_ylabel('CWND')\n",
    "    axs[i].axhline(y=packet_limits[i], color='r', linestyle='--', label=f'ECN Limit')\n",
    "    axs[i].axhline(y=bottleneck_limit, color='b', linestyle='--', label=f'Buffer Size')\n",
    "    axs[i].axhline(y=bottleneck_limit_cap, color='g', linestyle='--', label=f'Bottleneck Capacity')\n",
    "    axs[i].legend()  # Display the legend\n",
    "\n",
    "plt.tight_layout()  # Adjust subplots to fit into the figure area.\n",
    "fig.suptitle('100 Mbps Bottleneck Capacity -  2BDP Buffer Size - 25ms Base RTT - Single Queue FQ', y=1.05,fontsize=18)\n",
    "plt.savefig('plots.png', dpi=300)  # Adjust the file name and DPI as needed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c16fc4-952c-4a79-9d57-66a941f47e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume exp_factors_list is a list of dictionaries where each dictionary represents a set of parameters for an experiment\n",
    "def generate_column_names_and_limits(exp_lists):\n",
    "    column_names = []\n",
    "    limits = []\n",
    "    for exp in exp_lists:\n",
    "        name_tx0=\"%s_%0.1f_%d_%d_%s_%s_%d_%d\" % (exp['cc_tx0'],exp['n_bdp'], exp['btl_capacity'], exp['base_rtt'], exp['aqm'], str(exp.get('ecn_threshold', 'none')), exp['ecn_support'], exp['trial'])\n",
    "        column_names.append(name_tx0)\n",
    "\n",
    "        # Compute the limits\n",
    "        btl_cap = int(1000 * exp['btl_capacity'] * exp['base_rtt'] / 8)\n",
    "        btl_limit_noecn = int(btl_cap * (exp['n_bdp'] + 1))\n",
    "        ecn_threshold = exp.get('ecn_threshold', 0)\n",
    "        btl_limit_ecn = int(1000 * exp['btl_capacity'] * (exp['base_rtt'] + ecn_threshold) / 8)\n",
    "\n",
    "        packet_limit_ecn = int(btl_limit_ecn / 1500) + 1\n",
    "        bottleneck_limit = int(btl_limit_noecn / 1500) + 1\n",
    "        bottleneck_capacity_limit = int(btl_cap / 1500) + 1\n",
    "\n",
    "        limits.append((packet_limit_ecn, bottleneck_limit, bottleneck_capacity_limit))\n",
    "\n",
    "    return column_names, limits\n",
    "\n",
    "\n",
    "def generate_dynamic_titles(specified_params, avg_utilization):\n",
    "    included_keys = {'cc_tx0','ecn_threshold','ecn_support'}\n",
    "    excluded_keys = {'btl_capacity', 'base_rtt', 'n_bdp','aqm'}\n",
    "\n",
    "    title_map = {\n",
    "        'cc_tx0': lambda: f\"{specified_params['cc_tx0']}\",\n",
    "        'btl_capacity': lambda: f\"{specified_params['btl_capacity']} Mbps\",\n",
    "        'n_bdp': lambda: f\"{specified_params['n_bdp']} BDP\",\n",
    "        'base_rtt': lambda: f\"{specified_params['base_rtt']} ms RTT\",\n",
    "        'ecn_threshold': lambda: f\"ECN Threshold={specified_params['ecn_threshold']} ms\",\n",
    "        'ecn_support': lambda: f\"ECN Support={specified_params['ecn_support']}\",\n",
    "        'aqm': lambda: f\"AQM Type={specified_params['aqm']}\"\n",
    "    }\n",
    "\n",
    "    # Generate the main title with included keys\n",
    "    main_title = ' - '.join(val() for key, val in title_map.items() if key in included_keys and specified_params.get(key) is not None)\n",
    "    main_title += f\" - Average Utilization: {avg_utilization:.2f} %\"\n",
    "\n",
    "    # Generate the additional title with excluded keys\n",
    "    sup_title = ' - '.join(val() for key, val in title_map.items() if key in excluded_keys and specified_params.get(key) is not None)\n",
    "\n",
    "    return main_title, sup_title\n",
    "\n",
    "column_names, limits = generate_column_names_and_limits(exp_lists)\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv('/home/fabric/work/cwnd_tx0.csv')\n",
    "\n",
    "num_columns = len(column_names)\n",
    "fig, axs = plt.subplots(1, num_columns, figsize=(5 * num_columns + 15, 7))\n",
    "\n",
    "if num_columns == 1:\n",
    "    axs = [axs]  # Make it a list to keep the indexing consistent\n",
    "\n",
    "for i, column in enumerate(column_names):\n",
    "    avg_utilization = throughput_data[column]  # Get the average utilization for this column\n",
    "    dynamic_title, sup_title = generate_dynamic_titles(exp_lists[i], avg_utilization)\n",
    "    axs[i].plot(df.index, df[column])\n",
    "    axs[i].set_title(dynamic_title, fontsize=14)\n",
    "    axs[i].set_xlabel('Index')\n",
    "    axs[i].set_ylabel('CWND')\n",
    "    axs[i].axhline(y=limits[i][0], color='r', linestyle='--', label='ECN Limit')\n",
    "    axs[i].axhline(y=limits[i][1], color='b', linestyle='--', label='Buffer Size')\n",
    "    axs[i].axhline(y=limits[i][2], color='g', linestyle='--', label='Bottleneck Capacity')\n",
    "    axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(sup_title, y=1.05,fontsize=18) \n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
